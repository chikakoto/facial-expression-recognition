{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c1c3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import interp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbad5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = {0:'angry', 1:'disgust', 2:'fear', 3:'happy', 4:'sad', 5:'surprise', 6:'neutral'}\n",
    "target_labels = [val for key, val in emotion_labels.items()]\n",
    "targets = [key for key, val in emotion_labels.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf181220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, data_type):\n",
    "    \"\"\"Load data from DataFrame and return data to list \n",
    "    \"\"\"\n",
    "    image_data = []\n",
    "    image_scaled = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if data_type == 1:\n",
    "            field = row.pca\n",
    "        elif data_type == 2:\n",
    "            field = row.histogram\n",
    "        elif data_type == 3:\n",
    "            field = row.hog\n",
    "        elif data_type == 4:\n",
    "            field = row.lda\n",
    "        else:\n",
    "            field = row.pixels\n",
    "        image = np.fromstring(field, sep=' ')\n",
    "        image_data.append(image)\n",
    "        if data_type == 0:\n",
    "            scale = image / 255.0\n",
    "            image_scaled.append(scale)\n",
    "        \n",
    "    return image_data, image_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84e24ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usage</th>\n",
       "      <th>emotion</th>\n",
       "      <th>hog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   usage  emotion                                                hog\n",
       "0  train        3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "1  train        3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "2  train        3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "3  train        3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "4  train        3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/hog/hog_scaled2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b6f9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['usage']=='train']\n",
    "df_test = df[df['usage']=='test']\n",
    "train_data, train_scaled = load_data(df_train, 3)\n",
    "train_target = list(df_train.emotion)\n",
    "test_data, test_scaled = load_data(df_test, 3)\n",
    "test_target = list(df_test.emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519d0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_data)\n",
    "y_train = np.array(train_target)\n",
    "X_test = np.array(test_data)\n",
    "y_test = np.array(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c6c910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b721f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9590dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=2000,max_features='sqrt',\n",
    "                            random_state=101, n_jobs=-1,max_depth=60, min_samples_leaf=1, min_samples_split=2)\n",
    "\n",
    "svm = SVC(C=10.0, random_state=1, kernel='rbf', gamma='auto', decision_function_shape='ovo')\n",
    "knn = KNN(n_neighbors=2, weights='distance', metric='minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed68a1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn',\n",
       "                              KNeighborsClassifier(n_neighbors=2,\n",
       "                                                   weights='distance')),\n",
       "                             ('RF',\n",
       "                              RandomForestClassifier(max_depth=60,\n",
       "                                                     max_features='sqrt',\n",
       "                                                     n_estimators=2000,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=101)),\n",
       "                             ('SVM',\n",
       "                              SVC(C=10.0, decision_function_shape='ovo',\n",
       "                                  gamma='auto', random_state=1))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VotingClassifier(estimators=[('knn', knn), ('RF', rf),('SVM', svm)], voting='hard')\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61786e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"../../models/voting.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d2e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.998\n",
      "Test Accuracy: 0.560\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print('Train Accuracy: %.3f' % model.score(X_train, y_train))\n",
    "print('Test Accuracy: %.3f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89f7628c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.583\n",
      "Recall: 0.556\n",
      "F1: 0.556\n",
      "Accuracy: 0.560\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.42      0.37      0.40       957\n",
      "     disgust       0.85      1.00      0.92       830\n",
      "        fear       0.53      0.38      0.44      1024\n",
      "       happy       0.51      0.82      0.63      1774\n",
      "         sad       0.45      0.30      0.36      1247\n",
      "    surprise       0.84      0.59      0.70       831\n",
      "     neutral       0.48      0.43      0.45      1233\n",
      "\n",
      "    accuracy                           0.56      7896\n",
      "   macro avg       0.58      0.56      0.56      7896\n",
      "weighted avg       0.56      0.56      0.54      7896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='macro'))\n",
    "print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='macro'))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average='macro'))\n",
    "print('Accuracy: %.3f' % accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af49daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(cm,testscore):\n",
    "  '''provide cm item and test score'''\n",
    "  cm_labels_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "  cm_labels_norm = cm_labels_norm * 100.00\n",
    "\n",
    "  plt.figure(figsize=(9,9))\n",
    "  sns.heatmap(cm_labels_norm,\n",
    "              annot=True, \n",
    "              annot_kws={'size':16},\n",
    "              fmt=\".1f\",\n",
    "            cmap='Greens',\n",
    "            xticklabels=[i for i in emotions.values()],\n",
    "            yticklabels=[i for i in emotions.values()],\n",
    "            square=True,\n",
    "            cbar=False)\n",
    "  plt.title('Test Accuracy Score: {0}%\\n'.format(\"%.2f\" % (testscore*100.0)), size=24)\n",
    "  plt.tight_layout()\n",
    "  plt.xticks(size=14)\n",
    "  plt.yticks(size=14)\n",
    "  plt.ylabel('Actual label', size=18)\n",
    "  plt.xlabel('Predicted label', size=18)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbad5dc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_cm() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_cm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVoting Classifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHoG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_cm() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "plot_cm(confusion_matrix(y_test, y_pred), model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1f385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf28399",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = pickle.load(open(\"../../models/voting.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e87c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb13ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e7178",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores =\\\n",
    "                learning_curve(estimator=model,\n",
    "                               X=X_train,\n",
    "                               y=y_train,\n",
    "                               train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                               cv=10,\n",
    "                               n_jobs=1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
